{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Literature Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "from utils.Evidence_Retrieval.pubmedretrieval import PubMedRetrieval\n",
    "from camel.types import TaskType, ModelType,ModelPlatformType\n",
    "from utils.logging import setup_logging\n",
    "\n",
    "setup_logging()\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "YOUR_CONFIG_PATH = 'config/config.json' #  your config.json file\n",
    "YOUR_DATASET_PATH = 'data/2021ACR RA' # your dataset path\n",
    "YOUR_QUESTION_DECOMPOSITION_PATH =  'data/2021ACR RA/Question_Decomposition' # your question decomposition folder\n",
    "save_base =  \"data/2021ACR RA/Literature_Search/pubmed/Results\" #  search results folder\n",
    "\n",
    "disease = 'Rheumatoid Arthritis (RA)' # Disease name or clinical topic of your clinical question. \n",
    "pico_idx = \"ef0e4f95\" # PICO index of the clinical question, saved in your PICO_Information.json file\n",
    "\n",
    "# Search config\n",
    "additional_parameters = {'datetype': 'pdat', 'mindate': '1946', 'maxdate': '2025/03/30'} # pubmed parameters\n",
    "filters = {\"Just search for RCT\":'''<search results> AND (\"Randomized controlled trial\"[pt] OR \"Controlled clinical trial\"[pt] OR Randomized[tiab] OR Placebo[tiab] OR \"Drug therapy\"[sh] OR Randomly[tiab] OR Trial[tiab] OR Groups[tiab])''', 'No review': \"<search results> NOT review[pt]\"} # search filters: Dict[str, str]\n",
    "use_agent = True # whether to use Agentic method or not\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = os.path.join(YOUR_CONFIG_PATH)\n",
    "with open(config_path, 'r', encoding=\"utf8\") as file:\n",
    "            config = json.load(file)\n",
    "model_config = config['model'][\"literature_search_model\"]\n",
    "model_name = model_config['model_name']\n",
    "base_url = model_config['BASE_URL']\n",
    "api_key = model_config['API_KEY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_deconstruction_datapath = os.path.join(\n",
    "    YOUR_QUESTION_DECOMPOSITION_PATH, 'PICO_Information.json'\n",
    ")\n",
    "# load csv file\n",
    "question_deconstruction_data = pd.read_json(\n",
    "    question_deconstruction_datapath, dtype={'Index': str}\n",
    ")\n",
    "question_deconstruction_data = question_deconstruction_data[\n",
    "    question_deconstruction_data['Index'] == pico_idx\n",
    "]\n",
    "original_qd_dict = question_deconstruction_data.to_dict(orient='records')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_setting = {'search_term_formation': model_name,'search_strategy_formation':model_name}\n",
    "clinical_question = original_qd_dict[0]['Question']\n",
    "population = original_qd_dict[0]['P']\n",
    "intervention = original_qd_dict[0]['I']\n",
    "comparison = original_qd_dict[0]['C']\n",
    "save_path = os.path.join(save_base,model_name, 'use_agent_'+str(use_agent))\n",
    "pico_idx = original_qd_dict[0]['Index']\n",
    "retriever = PubMedRetrieval(disease=disease,clinical_question=clinical_question,population=population,intervention=intervention,comparison=comparison,api_key=api_key,base_url=base_url,model_setting=model_setting,use_agent=use_agent,save_path=save_path,pico_idx=pico_idx,filters=filters, additional_parameters=additional_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'population_terms': ['1. Rheumatoid arthritis',\n",
       "  '2. RA',\n",
       "  '3. Disease-modifying antirheumatic drugs',\n",
       "  '4. DMARDs',\n",
       "  '5. Low disease activity',\n",
       "  '6. Remission'],\n",
       " 'intervention_terms': ['1. Gradual taper',\n",
       "  '2. Withdrawal',\n",
       "  '3. Discontinuation',\n",
       "  '4. Dose reduction']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.search_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 156\n",
      "Records with abstract: 154\n",
      "Records after deduplication: 154\n"
     ]
    }
   ],
   "source": [
    "save_results_path = os.path.join(save_path, f'PICO{pico_idx}.json')\n",
    "with open(save_results_path, 'r', encoding=\"utf8\") as file:\n",
    "    search_results = json.load(file)\n",
    "\n",
    "# Heuristic screening\n",
    "# remove records without abstract\n",
    "print('Total records: '+str(len(search_results)))\n",
    "search_results = [record for record in search_results if record['Abstract'] != None]\n",
    "print('Records with abstract: '+str(len(search_results)))\n",
    "# deduplicate\n",
    "pmid_set = {d[\"Paper_Index\"] for d in search_results}\n",
    "for r in search_results:\n",
    "    if r[\"Paper_Index\"] in pmid_set:\n",
    "        pmid_set.remove(r[\"Paper_Index\"])\n",
    "    else:\n",
    "        search_results.remove(r)\n",
    "print('Records after deduplication: '+str(len(search_results)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pragmatic Clinical Trial', 'Clinical Trial, Phase II', \"Research Support, U.S. Gov't, P.H.S.\", 'Clinical Trial, Phase IV', 'Clinical Trial, Phase III', 'Observational Study', 'Clinical Trial', 'Journal Article', 'Multicenter Study', \"Research Support, Non-U.S. Gov't\", 'Comparative Study', 'Randomized Controlled Trial', 'Comment', 'Meta-Analysis', 'English Abstract', 'Retracted Publication', 'Clinical Trial Protocol', 'Research Support, N.I.H., Extramural', 'Case Reports', 'Clinical Trial, Phase I', 'Equivalence Trial'}\n"
     ]
    }
   ],
   "source": [
    "publication_type_set = {type for record in search_results for type in record['Publication Types']}\n",
    "print(publication_type_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records after removing invalid publication types: 136\n"
     ]
    }
   ],
   "source": [
    "# remove invalid publication types\n",
    "invalid_publication_types = ['Comment', 'Editorial', 'Case Reports', 'News', 'Interview','Published Erratum','Observational Study','Autobiography','Address','Meta-Analysis','Retracted Publication'] # you can modify this list according to your needs\n",
    "for record in search_results:\n",
    "    if any(pt in invalid_publication_types for pt in record['Publication Types']):\n",
    "        search_results.remove(record)\n",
    "print('Records after removing invalid publication types: '+str(len(search_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quicker data saved to data/2021ACR RA/quicker_data(PICO_IDXef0e4f95)_ls.json\n"
     ]
    }
   ],
   "source": [
    "# save the data as json\n",
    "quicker_data = {\n",
    "    \"disease\": disease,\n",
    "\t\"clinical_question\": clinical_question,\n",
    "    'pico_idx': pico_idx,\n",
    "\t\"population\": population,\n",
    "\t\"intervention\": intervention,\n",
    "\t\"comparison\": comparison,\n",
    "\t\"search_results\": search_results,\n",
    "}\n",
    "\n",
    "quicker_data_path = os.path.join(YOUR_DATASET_PATH, f'quicker_data(PICO_IDX{pico_idx})_ls.json')\n",
    "with open(quicker_data_path, 'w', encoding=\"utf8\") as file:\n",
    "    json.dump(quicker_data, file, indent=4)\n",
    "print(f\"Quicker data saved to {quicker_data_path}\")\n",
    "logging.info(f\"Quicker data saved to {quicker_data_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quicker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
