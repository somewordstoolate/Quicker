{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Literature Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "from utils.Evidence_Retrieval.pubmedretrieval import PubMedRetrieval\n",
    "from camel.types import TaskType, ModelType,ModelPlatformType\n",
    "from utils.logging import setup_logging\n",
    "\n",
    "setup_logging()\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "YOUR_CONFIG_PATH = 'YOUR_CONFIG_PATH' # e.g. 'config/config.json'\n",
    "YOUR_DATASET_PATH = 'YOUR_DATASET_PATH' # e.g. 'data/2021ACR RA'\n",
    "YOUR_QUESTION_DECOMPOSTITION_PATH =  'YOUR_QUESTION_DECOMPOSTITION_PATH' # e.g. 'data/2021ACR RA/Question_Decomposition'\n",
    "save_base =  \"your_results_save_base\" #  e.g. 'data/2021ACR RA/Search strategies/pubmed/Results'\n",
    "\n",
    "disease = 'disease_or_topic_of_your_question' # Disease name or clinical topic of your clinical question. e.g. 'Rheumatoid Arthritis (RA)'\n",
    "pico_idx = \"xxxxxxxxx\" # PICO index of the clinical question, saved in your PICO_Information.json file\n",
    "\n",
    "# Search config\n",
    "additional_parameters = {'datetype': 'pdat', 'mindate': '1946', 'maxdate': '2025/03/30'} # pubmed parameters\n",
    "filters = {\"Just search for RCT\":'''<search results> AND (\"Randomized controlled trial\"[pt] OR \"Controlled clinical trial\"[pt] OR Randomized[tiab] OR Placebo[tiab] OR \"Drug therapy\"[sh] OR Randomly[tiab] OR Trial[tiab] OR Groups[tiab])''', 'No review': \"<search results> NOT review[pt]\"} # search filters: Dict[str, str]\n",
    "use_agent = True # whether to use Agentic method or not\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = os.path.join(YOUR_CONFIG_PATH)\n",
    "with open(config_path, 'r', encoding=\"utf8\") as file:\n",
    "            config = json.load(file)\n",
    "model_config = config['model'][\"literature_search_model\"]\n",
    "model_name = model_config['model_name']\n",
    "base_url = model_config['BASE_URL']\n",
    "api_key = model_config['API_KEY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_deconstruction_datapath = os.path.join(\n",
    "    YOUR_QUESTION_DECOMPOSTITION_PATH, 'PICO_Information.json'\n",
    ")\n",
    "# load csv file\n",
    "question_deconstruction_data = pd.read_json(\n",
    "    question_deconstruction_datapath, dtype={'Index': str}\n",
    ")\n",
    "question_deconstruction_data = question_deconstruction_data[\n",
    "    question_deconstruction_data['Index'] == pico_idx\n",
    "]\n",
    "original_qd_dict = question_deconstruction_data.to_dict(orient='records')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_setting = {'search_term_formation': model_name,'search_strategy_formation':model_name}\n",
    "clinical_question = original_qd_dict[0]['Question']\n",
    "population = original_qd_dict[0]['P']\n",
    "intervention = original_qd_dict[0]['I']\n",
    "comparison = original_qd_dict[0]['C']\n",
    "save_path = os.path.join(save_base,model_name, 'use_agent_'+str(use_agent))\n",
    "pico_idx = original_qd_dict[0]['Index']\n",
    "retriever = PubMedRetrieval(disease=disease,clinical_question=clinical_question,population=population,intervention=intervention,comparison=comparison,api_key=api_key,base_url=base_url,model_setting=model_setting,use_agent=use_agent,save_path=save_path,pico_idx=pico_idx,filters=filters, additional_parameters=additional_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'population_terms': ['rheumatoid arthritis',\n",
       "  'RA',\n",
       "  'DMARD monotherapy',\n",
       "  'disease-modifying antirheumatic drugs'],\n",
       " 'intervention_terms': ['continuing treatment',\n",
       "  'treatment duration',\n",
       "  'treatment reassessment']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.search_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 2109\n",
      "Records with abstract: 2066\n",
      "Records after deduplication: 2066\n"
     ]
    }
   ],
   "source": [
    "save_results_path = os.path.join(save_path, f'PICO{pico_idx}.json')\n",
    "with open(save_results_path, 'r', encoding=\"utf8\") as file:\n",
    "    search_results = json.load(file)\n",
    "\n",
    "# Heuristic screening\n",
    "# remove records without abstract\n",
    "print('Total records: '+str(len(search_results)))\n",
    "search_results = [record for record in search_results if record['Abstract'] != None]\n",
    "print('Records with abstract: '+str(len(search_results)))\n",
    "# deduplicate\n",
    "pmid_set = {d[\"Paper_Index\"] for d in search_results}\n",
    "for r in search_results:\n",
    "    if r[\"Paper_Index\"] in pmid_set:\n",
    "        pmid_set.remove(r[\"Paper_Index\"])\n",
    "    else:\n",
    "        search_results.remove(r)\n",
    "print('Records after deduplication: '+str(len(search_results)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Case Reports', 'Editorial', 'Equivalence Trial', 'Clinical Trial, Phase IV', 'Comparative Study', 'Comment', 'Introductory Journal Article', 'Letter', 'Guideline', 'Clinical Trial, Phase I', 'Clinical Trial', \"Research Support, U.S. Gov't, P.H.S.\", 'Historical Article', 'Network Meta-Analysis', 'Clinical Trial, Phase III', 'Journal Article', 'Research Support, N.I.H., Extramural', \"Research Support, Non-U.S. Gov't\", 'Research Support, N.I.H., Intramural', 'English Abstract', \"Research Support, U.S. Gov't, Non-P.H.S.\", 'Pragmatic Clinical Trial', 'Observational Study', 'Research Support, American Recovery and Reinvestment Act', 'Meta-Analysis', 'Evaluation Study', 'Multicenter Study', 'Clinical Trial, Phase II', 'Randomized Controlled Trial', 'Controlled Clinical Trial', 'Practice Guideline', 'Lecture', 'Validation Study', 'Clinical Trial Protocol', 'Clinical Study'}\n"
     ]
    }
   ],
   "source": [
    "publication_type_set = {type for record in search_results for type in record['Publication Types']}\n",
    "print(publication_type_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records after removing invalid publication types: 1842\n"
     ]
    }
   ],
   "source": [
    "# remove invalid publication types\n",
    "invalid_publication_types = ['Comment', 'Editorial', 'Case Reports', 'News', 'Interview','Published Erratum','Observational Study','Autobiography','Address','Meta-Analysis','Retracted Publication'] # you can modify this list according to your needs\n",
    "for record in search_results:\n",
    "    if any(pt in invalid_publication_types for pt in record['Publication Types']):\n",
    "        search_results.remove(record)\n",
    "print('Records after removing invalid publication types: '+str(len(search_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data as json\n",
    "quicker_data = {\n",
    "    \"disease\": disease,\n",
    "\t\"clinical_question\": clinical_question,\n",
    "    'pico_idx': pico_idx,\n",
    "\t\"population\": population,\n",
    "\t\"intervention\": intervention,\n",
    "\t\"comparison\": comparison,\n",
    "\t\"search_results\": search_results,\n",
    "}\n",
    "\n",
    "quicker_data_path = os.path.join(YOUR_DATASET_PATH, f'quicker_data(PICO_IDX{pico_idx})_ls.json')\n",
    "with open(quicker_data_path, 'w', encoding=\"utf8\") as file:\n",
    "    json.dump(quicker_data, file, indent=4)\n",
    "print(f\"Quicker data saved to {quicker_data_path}\")\n",
    "logging.info(f\"Quicker data saved to {quicker_data_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quicker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
